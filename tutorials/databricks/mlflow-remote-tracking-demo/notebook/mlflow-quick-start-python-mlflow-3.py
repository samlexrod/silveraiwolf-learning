# Databricks notebook source
# MAGIC %md # MLflow example (Python) (MLflow 3.0)
# MAGIC
# MAGIC With MLflow's autologging capabilities, a single line of code automatically logs the resulting model, the parameters used to create the model, and model metrics. MLflow autologging is available for several widely used machine learning packages. This notebook creates a Random Forest model on a simple dataset and uses the the MLflow `autolog()` function to log information generated by the run.
# MAGIC
# MAGIC This tutorial leverages features from MLflow 3.0. For more details, see "Get started with MLflow 3.0" ([AWS](https://docs.databricks.com/aws/en/mlflow/mlflow-3-install)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/mlflow/mlflow-3-install)|[GCP](https://docs.databricks.com/gcp/en/mlflow/mlflow-3-install))
# MAGIC
# MAGIC For details about what information is logged with `autolog()`, refer to the [MLflow documentation](https://mlflow.org/docs/latest/index.html). 

# COMMAND ----------

# MAGIC %md Install the mlflow library, upgrading to MLflow 3.0

# COMMAND ----------

# Upgrade to the latest MLflow version to use MLflow 3.0 features
%pip install mlflow>=3.0 --upgrade
dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %md Import the required libraries.

# COMMAND ----------

import mlflow
import mlflow.sklearn
import pandas as pd
import matplotlib.pyplot as plt

from numpy import savetxt

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# COMMAND ----------

# MAGIC %md Import the dataset from scikit-learn and create the training and test datasets. 

# COMMAND ----------

db = load_diabetes()
X = db.data
y = db.target
X_train, X_test, y_train, y_test = train_test_split(X, y)

# COMMAND ----------

# MAGIC %md
# MAGIC The diabetes dataset from scikit-learn consists of 442 samples with 10 features, used to predict disease progression. The features are:
# MAGIC
# MAGIC - **age**: Age of the patient (standardized)
# MAGIC - **sex**: Sex of the patient (standardized)
# MAGIC - **bmi**: Body mass index (standardized)
# MAGIC - **bp**: Average blood pressure (standardized)
# MAGIC - **s1**: Serum 1 (TC, total cholesterol, standardized)
# MAGIC - **s2**: Serum 2 (LDL, low-density lipoproteins, standardized)
# MAGIC - **s3**: Serum 3 (HDL, high-density lipoproteins, standardized)
# MAGIC - **s4**: Serum 4 (TCH, total cholesterol/HDL ratio, standardized)
# MAGIC - **s5**: Serum 5 (LTG, possibly log of serum triglycerides, standardized)
# MAGIC - **s6**: Serum 6 (GLU, blood sugar level, standardized)
# MAGIC
# MAGIC The target variable is a quantitative measure of disease progression one year after baseline.
# MAGIC
# MAGIC - **Low progression**: Indicates less severe worsening of diabetes symptoms or slower disease advancement.
# MAGIC - **High progression**: Indicates more severe worsening of diabetes symptoms or faster disease advancement.
# MAGIC
# MAGIC This notebook demonstrates a **regression** task, where the goal is to predict a continuous value (disease progression) from input features. Regression learns the relationship between features and the target from training data and can make predictions for new, unseen data. This is different from **interpolation**, which estimates unknown values strictly within the range of known data points without learning a model from data.
# MAGIC
# MAGIC Regression models, such as RandomForestRegressor, can also **extrapolate**, meaning they can make predictions for input feature values that fall outside the range of the training data. However, the accuracy of extrapolated predictions is often lower because the model has not seen such data during training. In contrast, interpolation only estimates values within the range of the observed data and does not generalize beyond it.

# COMMAND ----------

pd.DataFrame(data=db.data, columns=db.feature_names).assign(target=db.target)

# COMMAND ----------

# MAGIC %md Create a random forest model and log parameters, metrics, and the model using `mlflow.sklearn.autolog()`.

# COMMAND ----------

# Enable autolog()
mlflow.sklearn.autolog()

# With autolog() enabled, a logged model is automatically created under the experiment
# All parameters and metrics are automatically logged to both the model and run
with mlflow.start_run():
  
  # Set the model parameters. 
  n_estimators = 100
  max_depth = 6
  max_features = 3
  
  # Create and train model.
  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)
  rf.fit(X_train, y_train)
  
  # Use the model to make predictions on the test dataset.
  predictions = rf.predict(X_test)

# COMMAND ----------

# MAGIC %md To view the results, click the **Experiments** icon <img src="https://docs.databricks.com/_static/images/icons/experiment.png"/> in the right sidebar. This sidebar displays the parameters and metrics for each run of this notebook.
# MAGIC
# MAGIC Click the name of the run to open the Runs page in a new tab. This page shows all of the information that was logged from the run. Select the **Artifacts** tab to find the plot.
# MAGIC
# MAGIC From the experiments page, switch to the **Models** tab to view the logged model that was created, along with all relevant metadata such as parameters and metrics.
# MAGIC
# MAGIC For more information, see "MLflow experiments" ([AWS](https://docs.databricks.com/aws/en/mlflow/experiments)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/mlflow/experiments)|[GCP](https://docs.databricks.com/gcp/en/mlflow/experiments)).
