{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528c6d2b-3c5a-4236-ac61-fa8cc8d4d323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow logging API example (Python) (MLflow 3.0)\n",
    "\n",
    "This notebook illustrates how to use the MLflow logging API to start an MLflow run and log the model, model parameters, evaluation metrics, and other artifacts to the logged model and run. The easiest way to get started using MLflow tracking with Python is to use the MLflow [`autolog()` API](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging). If you need more control over the metrics logged for each training run, or want to log additional artifacts such as tables or plots, you can use the `mlflow.log_metric()`, and `mlflow.log_artifact()` APIs demonstrated in this notebook. \n",
    "\n",
    "This tutorial leverages features from MLflow 3.0. For more details, see \"Get started with MLflow 3.0\" ([AWS](https://docs.databricks.com/aws/en/mlflow/mlflow-3-install)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/mlflow/mlflow-3-install)|[GCP](https://docs.databricks.com/gcp/en/mlflow/mlflow-3-install))\n",
    "\n",
    "This notebook creates a Random Forest model on a simple dataset and uses the MLflow Tracking API to log the model and selected model parameters and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a2fcdc4-14f3-4db6-9a1a-85cfa94dfb18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6ad9db8-7499-40e8-9a92-bc91140f394f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee52ec16-6ddf-4cdd-a391-7d172984980a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Upgrade to the latest MLflow version to use MLflow 3.0 features\n",
    "%pip install mlflow>=3.0 --upgrade\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b1f2b42-7670-4ac6-9f14-40e29cc9c122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec61d6d-ea1a-4d2f-9ee6-625393a24aa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import savetxt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b8e9ea-2046-48e0-bb26-d71c6669e66e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import the dataset from scikit-learn and create the training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e835da93-ac8c-4250-ab85-608ba2f280a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db = load_diabetes()\n",
    "X = db.data\n",
    "y = db.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb3cdb68-fa1d-43ec-bf69-a91f4fdab528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The diabetes dataset from scikit-learn consists of 442 samples with 10 features, used to predict disease progression. The features are:\n",
    "\n",
    "- **age**: Age of the patient (standardized)\n",
    "- **sex**: Sex of the patient (standardized)\n",
    "- **bmi**: Body mass index (standardized)\n",
    "- **bp**: Average blood pressure (standardized)\n",
    "- **s1**: Serum 1 (TC, total cholesterol, standardized)\n",
    "- **s2**: Serum 2 (LDL, low-density lipoproteins, standardized)\n",
    "- **s3**: Serum 3 (HDL, high-density lipoproteins, standardized)\n",
    "- **s4**: Serum 4 (TCH, total cholesterol/HDL ratio, standardized)\n",
    "- **s5**: Serum 5 (LTG, possibly log of serum triglycerides, standardized)\n",
    "- **s6**: Serum 6 (GLU, blood sugar level, standardized)\n",
    "\n",
    "The target variable is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "- **Low progression**: Indicates less severe worsening of diabetes symptoms or slower disease advancement.\n",
    "- **High progression**: Indicates more severe worsening of diabetes symptoms or faster disease advancement.\n",
    "\n",
    "This notebook demonstrates a **regression** task, where the goal is to predict a continuous value (disease progression) from input features. Regression learns the relationship between features and the target from training data and can make predictions for new, unseen data. This is different from **interpolation**, which estimates unknown values strictly within the range of known data points without learning a model from data.\n",
    "\n",
    "Regression models, such as RandomForestRegressor, can also **extrapolate**, meaning they can make predictions for input feature values that fall outside the range of the training data. However, the accuracy of extrapolated predictions is often lower because the model has not seen such data during training. In contrast, interpolation only estimates values within the range of the observed data and does not generalize beyond it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1117f314-a750-4abd-a482-53779a70cc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=db.data, columns=db.feature_names).assign(target=db.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "278efa84-dc0e-4a33-b722-9a9104c2d957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create a random forest model and log the model, model parameters, evaluation metrics, and other artifacts using `mlflow.log_param()`, `mlflow.log_metric()`, `mlflow.log_model()`, and `mlflow.log_artifact()`. These functions let you control exactly which parameters and metrics are logged, and also let you log other artifacts of the run such as tables and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a01be4a7-c6f6-493a-bad0-19e378a47607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "  \n",
    "  # Set the model parameters. \n",
    "  n_estimators = 100\n",
    "  max_depth = 6\n",
    "  max_features = 3\n",
    "  params = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"max_features\": max_features\n",
    "  }\n",
    "\n",
    "  # Log the model parameters used for this run.\n",
    "  mlflow.log_params(params)\n",
    "  \n",
    "  # Create and train model.\n",
    "  rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  # Log the model create by this run, creating a Logged Model which inherits the parameters\n",
    "  logged_model = mlflow.sklearn.log_model(rf, name=\"random-forest-model\", input_example=X_train)\n",
    "  \n",
    "  # Use the model to make predictions on the test dataset.\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Define a metric to use to evaluate the model.\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "    \n",
    "  # Log the value of the metric from this run, linking to the logged model\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  # Save the table of predicted values\n",
    "  savetxt('predictions.csv', predictions, delimiter=',')\n",
    "  \n",
    "  # Log the saved table as an artifact\n",
    "  mlflow.log_artifact(\"predictions.csv\")\n",
    "  \n",
    "  # Convert the residuals to a pandas dataframe to take advantage of graphics capabilities\n",
    "  df = pd.DataFrame(data = predictions - y_test)\n",
    "  \n",
    "  # Create a plot of residuals\n",
    "  plt.plot(df)\n",
    "  plt.xlabel(\"Observation\")\n",
    "  plt.ylabel(\"Residual\")\n",
    "  plt.title(\"Residuals\")\n",
    "\n",
    "  # Save the plot and log it as an artifact\n",
    "  plt.savefig(\"residuals_plot.png\")\n",
    "  mlflow.log_artifact(\"residuals_plot.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16d8bec5-d4da-4680-91e0-da5da79cfd6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To view the results, click the **Experiments** icon <img src=\"https://docs.databricks.com/_static/images/icons/experiment.png\"/> in the right sidebar. This sidebar displays the parameters and metrics for each run of this notebook.\n",
    "\n",
    "Click the name of the run to open the Runs page in a new tab. This page shows all of the information that was logged from the run. Select the **Artifacts** tab to find the logged model and plot.\n",
    "\n",
    "From the experiments page, switch to the **Models** tab to view the logged model that was created, along with all relevant metadata such as parameters and metrics.\n",
    "\n",
    "For more information, see \"MLflow experiments\" ([AWS](https://docs.databricks.com/applications/mlflow/experiments.html)|[Azure](https://docs.microsoft.com/azure/databricks/applications/mlflow/experiments)|[GCP](https://docs.gcp.databricks.com/applications/mlflow/experiments.html))."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "mlflow-logging-api-quick-start-python-mlflow-3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
