{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce20582-b595-440e-b7e7-86ab5e6e042c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow 3.0 traditional ML example\n",
    "\n",
    "This notebook first runs a model training job, which is tracked as an MLflow Run, to produce a trained model. The model is tracked as an MLflow Logged Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8189b4a3-642a-4f4d-96be-15c90d5d784c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow>=3.0 --upgrade\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d180c18-8c8f-4628-8860-166c2ef5e1c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.entities import Dataset\n",
    "\n",
    "# Helper function to compute metrics\n",
    "def compute_metrics(actual, predicted):\n",
    "    rmse = mean_squared_error(actual, predicted)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "# Load Iris dataset and prepare the DataFrame\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['quality'] = (iris.target == 2).astype(float)  # Create a binary target for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff5e08f-b3a5-48b5-b536-4ba0f4409096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this example, we are predicting whether an iris flower belongs to the species \"virginica\" (class 2 in the Iris dataset). The target variable is the \"quality\" column, which is set to 1 if the flower is \"virginica\" and 0 otherwise. This is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4daa5ff3-64a4-4413-8e1e-da1a7dc3e368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8940971-97e0-4d62-8382-beb76f87d3c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ElasticNet is a linear model for regression that combines both L1 (Lasso) and L2 (Ridge) regularization. It helps prevent overfitting by penalizing large coefficients and can select important features by shrinking some coefficients to zero. The balance between L1 and L2 regularization is controlled by the l1_ratio parameter.\n",
    "\n",
    "L1 regularization (Lasso) adds a penalty equal to the absolute value of the coefficients, which can drive some coefficients to exactly zero, effectively performing feature selection.\n",
    "\n",
    "L2 regularization (Ridge) adds a penalty equal to the square of the coefficients, which shrinks coefficients towards zero but does not set them exactly to zero.\n",
    "\n",
    "In this example, we are using the l1_ratio parameter (set to 0.5) in the ElasticNet model, which means the regularization is an equal mix of L1 (Lasso) and L2 (Ridge) penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5513ea7b-bb54-4713-8d13-f6be91bfb1a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following steps are performed in the workflow:\n",
    "\n",
    "1. Log the trained ElasticNet model using `mlflow.sklearn.log_model()`, which creates a `LoggedModel` entity in MLflow and stores the model artifact and its parameters.\n",
    "2. Retrieve the logged model using `mlflow.get_logged_model()`, allowing access to the model's metadata, such as its model ID and parameters.\n",
    "3. Log training metrics using `mlflow.log_metrics()`, linking the metrics to the specific `LoggedModel` by its model ID and to the dataset used for evaluation. This ensures that the model, its parameters, and all associated metrics and datasets are tracked and linked together for comprehensive observability and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1039bbbd-b7a2-4d94-a230-98f625dff009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split into training and testing datasets\n",
    "train_df, test_df = train_test_split(iris_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start a run to represent the training job\n",
    "with mlflow.start_run() as training_run:\n",
    "    # Load the training dataset with MLflow. We will link training metrics to this dataset.\n",
    "    train_dataset: Dataset = mlflow.data.from_pandas(train_df, name=\"train\")\n",
    "    train_x = train_dataset.df.drop([\"quality\"], axis=1)\n",
    "    train_y = train_dataset.df[[\"quality\"]]\n",
    "\n",
    "    # Fit a model to the training dataset\n",
    "    lr = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    # Log the model, specifying its ElasticNet parameters (alpha, l1_ratio)\n",
    "    # As a new feature, the LoggedModel entity is linked to its name and params\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        name=\"elasticnet\",\n",
    "        params={\n",
    "            \"alpha\": 0.5,\n",
    "            \"l1_ratio\": 0.5,\n",
    "        },\n",
    "        input_example = train_x\n",
    "    )\n",
    "\n",
    "    # Inspect the LoggedModel and its properties\n",
    "    logged_model = mlflow.get_logged_model(model_info.model_id)\n",
    "    print(logged_model.model_id, logged_model.params)\n",
    "\n",
    "    # Evaluate the model on the training dataset and log metrics\n",
    "    # These metrics are now linked to the LoggedModel entity\n",
    "    predictions = lr.predict(train_x)\n",
    "    (rmse, mae, r2) = compute_metrics(train_y, predictions)\n",
    "    mlflow.log_metrics(\n",
    "        metrics={\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2,\n",
    "            \"mae\": mae,\n",
    "        },\n",
    "        model_id=logged_model.model_id,\n",
    "        dataset=train_dataset\n",
    "    )\n",
    "\n",
    "    # Inspect the LoggedModel, now with metrics\n",
    "    logged_model = mlflow.get_logged_model(model_info.model_id)\n",
    "    print(logged_model.model_id, logged_model.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b018b412-671f-4520-97bc-4a7dd80dc2d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Some time later, when you get a new evaluation dataset based on the latest production data, you can run a new model evaluation job, which is tracked as a new MLflow Run, to measure the performance of the model on this new dataset.\n",
    "\n",
    "This example produces two MLflow Runs (`training_run` and `evaluation_run`) and one MLflow `LoggedModel` (`elasticnet`). From the resulting `LoggedModel`, you can see all of the parameters and metadata, as well as all of the metrics linked from the training and evaluation runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85482df-7d3f-47c7-8d2d-6dd6935f0e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start a run to represent the test dataset evaluation job\n",
    "with mlflow.start_run() as evaluation_run:\n",
    "  # Load the test dataset with MLflow. We will link test metrics to this dataset.\n",
    "  test_dataset: mlflow.entities.Dataset = mlflow.data.from_pandas(test_df, name=\"test\")\n",
    "  test_x = test_dataset.df.drop([\"quality\"], axis=1)\n",
    "  test_y = test_dataset.df[[\"quality\"]]\n",
    "\n",
    "  # Load the model\n",
    "  model = mlflow.sklearn.load_model(f\"models:/{logged_model.model_id}\")\n",
    "\n",
    "  # Evaluate the model on the training dataset and log metrics, linking to model\n",
    "  predictions = model.predict(test_x)\n",
    "  (rmse, mae, r2) = compute_metrics(test_y, predictions)\n",
    "  mlflow.log_metrics(\n",
    "    metrics={\n",
    "      \"rmse\": rmse,\n",
    "      \"r2\": r2,\n",
    "      \"mae\": mae,\n",
    "    },\n",
    "    dataset=test_dataset,\n",
    "    model_id=logged_model.model_id\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed77111-a9a9-44eb-819a-41f2f05fc976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(mlflow.get_logged_model(logged_model.model_id).to_dictionary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7beda3-86cc-4553-8de4-0c9e914b86eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now register the model to UC. You can also see the model ID, parameters, and metrics in the UC Model Version page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c28c30f6-7271-440a-b2c8-412b52adfff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You must have `USE CATALOG` privileges on the catalog, and you must have `USE SCHEMA` privileges on the schema.\n",
    "# If necessary, change the catalog and schema name here.\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"default\"\n",
    "MODEL = \"ml_model\"\n",
    "MODEL_NAME = f\"{CATALOG}.{SCHEMA}.{MODEL}\"\n",
    "\n",
    "uc_model_version = mlflow.register_model(model_info.model_uri, name=MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18dcab9d-5b70-4940-a273-b9911385fa55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now you can view the model version and all centralized performance data on the model version page in Unity Catalog. You can also get the same information using the API as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8481e0e-57ad-4a6e-a297-1a6602a10636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Model Name: {MODEL_NAME}\n",
    "Model Version: {uc_model_version.version} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd331b5b-92d0-4cbb-8bf0-ca20c25f596d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the model version\n",
    "from mlflow import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_version = client.get_model_version(name=MODEL_NAME, version=uc_model_version.version)\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f16468-6f94-4329-962e-289f5132a674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import pyfunc\n",
    "\n",
    "model_version_number = uc_model_version.version\n",
    "registered_model_uri = f\"models:/{MODEL_NAME}/{model_version_number}\"\n",
    "loaded_model = mlflow.pyfunc.load_model(registered_model_uri)\n",
    "\n",
    "sample = test_df.drop([\"quality\"], axis=1).iloc[[0]]\n",
    "prediction = loaded_model.predict(sample)\n",
    "print(f\"Prediction for sample: {prediction[0]}\")\n",
    "print(f\"Actual label: {test_df.iloc[0]['quality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a086c44b-4a0a-423d-a625-2bf53c35c429",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "mlflow3-ml-example",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
